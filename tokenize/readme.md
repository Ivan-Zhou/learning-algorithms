# Tokenization
## Byte Pair Encoding (BPE)
Byte Pair Encoding (BPE) is a data compression algorithm that iteratively replaces the most frequently occurring pair of bytes in a sequence with a single, unused byte. The process is repeated until a desired compression ratio is achieved. BPE is commonly used in natural language processing tasks such as machine translation and text generation to deal with out-of-vocabulary words and reduce the size of the vocabulary.

BPE is used in GPT2, LLaMA, OPT, and Pythia.
